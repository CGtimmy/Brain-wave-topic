{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c6aa3-9fb2-4b3d-a969-c70a96e56a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# 設定路徑\n",
    "WATCH_FOLDER = '/Users/hoyi/Desktop/HI'\n",
    "RESULT_FILE = '/Users/hoyi/Desktop/new.txt'\n",
    "MODEL_PATH = '/Users/hoyi/Downloads/eeg_model/random_forest_model.joblib'\n",
    "SCALER_PATH = '/Users/hoyi/Downloads/eeg_model/standard_scaler.joblib'\n",
    "\n",
    "# 載入模型和標準化器\n",
    "model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# 已處理過的檔案集合\n",
    "processed_files = set()\n",
    "\n",
    "class NewFileHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory:\n",
    "            return\n",
    "            \n",
    "        if event.src_path.endswith('.txt') and event.src_path not in processed_files:\n",
    "            print(f\"偵測到新檔案: {event.src_path}\")\n",
    "            process_file(event.src_path)\n",
    "            processed_files.add(event.src_path)\n",
    "\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        # 讀取檔案內容\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read().strip()\n",
    "            \n",
    "        # 解析數值\n",
    "        try:\n",
    "            beta, alpha = map(float, content.split(','))\n",
    "            features = np.array([[beta, alpha]])\n",
    "            \n",
    "            # 標準化特徵\n",
    "            features_scaled = scaler.transform(features)\n",
    "            \n",
    "            # 預測 (直接得到 1, 2 或 3)\n",
    "            prediction = model.predict(features_scaled)[0]\n",
    "            \n",
    "            # 只寫入預測數字到結果文件\n",
    "            with open(RESULT_FILE, 'a') as f:\n",
    "                f.write(f\"{prediction}\\n\")\n",
    "                \n",
    "            print(f\"處理完成: {file_path} -> 預測類別: {prediction}\")\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"檔案內容格式錯誤: {file_path} - {str(e)}\")\n",
    "            with open(RESULT_FILE, 'a') as f:\n",
    "                f.write(\"格式錯誤\\n\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"處理檔案時發生錯誤: {file_path} - {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # 初始化監控\n",
    "    event_handler = NewFileHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, WATCH_FOLDER, recursive=False)\n",
    "    observer.start()\n",
    "    \n",
    "    # 檢查已存在的檔案\n",
    "    for filename in os.listdir(WATCH_FOLDER):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(WATCH_FOLDER, filename)\n",
    "            if file_path not in processed_files:\n",
    "                process_file(file_path)\n",
    "                processed_files.add(file_path)\n",
    "    \n",
    "    print(f\"開始監控資料夾: {WATCH_FOLDER}\")\n",
    "    print(f\"結果將寫入: {RESULT_FILE} (只包含預測數字 1, 2 或 3)\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化結果文件 (如果不存在則創建)\n",
    "    if not os.path.exists(RESULT_FILE):\n",
    "        with open(RESULT_FILE, 'w') as f:\n",
    "            pass  # 創建空文件\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1dfd6-593a-44d2-a110-d3c83fecaea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "監控資料夾: /Users/hoyi/Desktop/HI\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234.txt\n",
      "累積基準值資料：1/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝.txt\n",
      "累積基準值資料：2/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝2.txt\n",
      "累積基準值資料：3/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝3.txt\n",
      "累積基準值資料：4/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝4.txt\n",
      "累積基準值資料：5/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝5.txt\n",
      "累積基準值資料：6/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝6.txt\n",
      "累積基準值資料：7/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝7.txt\n",
      "累積基準值資料：8/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝8.txt\n",
      "累積基準值資料：9/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝9.txt\n",
      "累積基準值資料：10/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝10.txt\n",
      "累積基準值資料：11/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝11.txt\n",
      "累積基準值資料：12/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝12.txt\n",
      "累積基準值資料：13/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝13.txt\n",
      "累積基準值資料：14/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝14.txt\n",
      "累積基準值資料：15/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝15.txt\n",
      "累積基準值資料：16/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝16.txt\n",
      "累積基準值資料：17/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝17.txt\n",
      "累積基準值資料：18/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝20.txt\n",
      "累積基準值資料：19/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝18.txt\n",
      "累積基準值資料：20/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝19.txt\n",
      "累積基準值資料：21/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝21.txt\n",
      "累積基準值資料：22/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝22.txt\n",
      "累積基準值資料：23/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝23.txt\n",
      "累積基準值資料：24/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝24.txt\n",
      "累積基準值資料：25/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝25.txt\n",
      "累積基準值資料：26/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝26.txt\n",
      "累積基準值資料：27/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝27.txt\n",
      "累積基準值資料：28/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝28.txt\n",
      "累積基準值資料：29/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝29.txt\n",
      "累積基準值資料：30/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝30.txt\n",
      "累積基準值資料：31/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝31.txt\n",
      "累積基準值資料：32/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝32.txt\n",
      "累積基準值資料：33/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝33.txt\n",
      "累積基準值資料：34/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝34.txt\n",
      "累積基準值資料：35/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝35.txt\n",
      "累積基準值資料：36/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝36.txt\n",
      "累積基準值資料：37/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝37.txt\n",
      "累積基準值資料：38/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝38.txt\n",
      "累積基準值資料：39/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝39.txt\n",
      "累積基準值資料：40/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝40.txt\n",
      "累積基準值資料：41/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝41.txt\n",
      "累積基準值資料：42/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝42.txt\n",
      "累積基準值資料：43/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝43.txt\n",
      "累積基準值資料：44/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝44.txt\n",
      "累積基準值資料：45/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝45.txt\n",
      "累積基準值資料：46/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝46.txt\n",
      "累積基準值資料：47/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝47.txt\n",
      "累積基準值資料：48/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝48.txt\n",
      "累積基準值資料：49/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝49.txt\n",
      "累積基準值資料：50/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝50.txt\n",
      "累積基準值資料：51/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝51.txt\n",
      "累積基準值資料：52/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝52.txt\n",
      "累積基準值資料：53/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝53.txt\n",
      "累積基準值資料：54/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝54.txt\n",
      "累積基準值資料：55/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝55.txt\n",
      "累積基準值資料：56/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝56.txt\n",
      "累積基準值資料：57/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝57.txt\n",
      "累積基準值資料：58/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝58.txt\n",
      "累積基準值資料：59/60\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝59.txt\n",
      "累積基準值資料：60/60\n",
      "已建立基準，刪除 0 筆離群，alpha_avg=366.3529, beta_avg=191.5045\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝60.txt\n",
      "標準化後 alpha: 0.0000, beta: 0.0000\n",
      "分類結果: 2\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝61.txt\n",
      "標準化後 alpha: 0.0000, beta: 0.0000\n",
      "分類結果: 2\n",
      "偵測到新檔案: /Users/hoyi/Desktop/HI/FFT_Data_20250405160234拷貝62.txt\n",
      "標準化後 alpha: 0.0000, beta: 0.0000\n",
      "分類結果: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "WATCH_FOLDER = '/Users/hoyi/Desktop/HI'\n",
    "RESULT_FILE = '/Users/hoyi/Desktop/cluster_result.txt'\n",
    "MODEL_PATH = '/Users/hoyi/Downloads/eeg_model/random_forest_model.joblib'\n",
    "SCALER_PATH = '/Users/hoyi/Downloads/eeg_model/standard_scaler.joblib'\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "alpha_list = []\n",
    "beta_list = []\n",
    "alpha_avg = None\n",
    "beta_avg = None\n",
    "alpha_upper = None\n",
    "beta_upper = None\n",
    "alpha_lower = None\n",
    "beta_lower = None\n",
    "baseline_samples = 60\n",
    "processed_files = set()\n",
    "deleted_count = 0\n",
    "\n",
    "class EEGFileHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith('.txt'):\n",
    "            return\n",
    "\n",
    "        print(f\"偵測到新檔案: {event.src_path}\")\n",
    "        process_file(event.src_path)\n",
    "\n",
    "def process_file(filepath):\n",
    "    global alpha_list, beta_list\n",
    "    global alpha_avg, beta_avg, alpha_upper, beta_upper, alpha_lower, beta_lower, deleted_count\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        data = np.array([float(x.strip()) for x in lines])\n",
    "\n",
    "        if len(data) < 28:\n",
    "            print(\"資料不足\")\n",
    "            return\n",
    "\n",
    "        alpha = np.mean(data[7:12])\n",
    "        beta = np.mean(data[11:28])\n",
    "\n",
    "        if len(alpha_list) < baseline_samples:\n",
    "            alpha_list.append(alpha)\n",
    "            beta_list.append(beta)\n",
    "            print(f\"累積基準值資料：{len(alpha_list)}/{baseline_samples}\")\n",
    "            if len(alpha_list) == baseline_samples:\n",
    "                alpha_q1, alpha_q3 = np.percentile(alpha_list, [25, 75])\n",
    "                beta_q1, beta_q3 = np.percentile(beta_list, [25, 75])\n",
    "\n",
    "                alpha_upper = alpha_q3 + 1.5 * (alpha_q3 - alpha_q1)\n",
    "                alpha_lower = alpha_q1 - 1.5 * (alpha_q3 - alpha_q1)\n",
    "                beta_upper = beta_q3 + 1.5 * (beta_q3 - beta_q1)\n",
    "                beta_lower = beta_q1 - 1.5 * (beta_q3 - beta_q1)\n",
    "\n",
    "                # 同時為離群值者移除\n",
    "                keep_indices = ~((np.array(alpha_list) < alpha_lower) | (np.array(alpha_list) > alpha_upper)) | \\\n",
    "                               ~((np.array(beta_list) < beta_lower) | (np.array(beta_list) > beta_upper))\n",
    "\n",
    "                removed = baseline_samples - np.sum(keep_indices)\n",
    "                alpha_list = list(np.array(alpha_list)[keep_indices])\n",
    "                beta_list = list(np.array(beta_list)[keep_indices])\n",
    "                deleted_count += removed\n",
    "\n",
    "                alpha_avg = np.mean(alpha_list)\n",
    "                beta_avg = np.mean(beta_list)\n",
    "\n",
    "                print(f\"已建立基準，刪除 {removed} 筆離群，alpha_avg={alpha_avg:.4f}, beta_avg={beta_avg:.4f}\")\n",
    "            return\n",
    "\n",
    "        # 已建立基準，進行判斷\n",
    "        if alpha_lower <= alpha <= alpha_upper and beta_lower <= beta <= beta_upper:\n",
    "            alpha_norm = (alpha - alpha_avg) / alpha_avg\n",
    "            beta_norm = (beta - beta_avg) / beta_avg\n",
    "            print(f\"標準化後 alpha: {alpha_norm:.4f}, beta: {beta_norm:.4f}\")\n",
    "\n",
    "            features = np.array([[beta_norm, alpha_norm]])\n",
    "            features_scaled = scaler.transform(features)\n",
    "            prediction = model.predict(features_scaled)[0]\n",
    "\n",
    "            with open(RESULT_FILE, 'a') as f:\n",
    "                f.write(f\"{prediction}\\n\")\n",
    "\n",
    "            print(f\"分類結果: {prediction}\")\n",
    "        else:\n",
    "            deleted_count += 1\n",
    "            print(f\"檔案 {os.path.basename(filepath)} 為離群值，已忽略（總刪除: {deleted_count}）\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"處理錯誤: {filepath} - {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(RESULT_FILE):\n",
    "        with open(RESULT_FILE, 'w') as f:\n",
    "            pass\n",
    "\n",
    "    event_handler = EEGFileHandler()\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, WATCH_FOLDER, recursive=False)\n",
    "    observer.start()\n",
    "\n",
    "    print(f\"監控資料夾: {WATCH_FOLDER}\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae48bde8-b848-4887-a743-f937e1153ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型已成功導出至: /Users/hoyi/Downloads/eeg_model3/random_forest_model.joblib\n",
      "標準化器已成功導出至: /Users/hoyi/Downloads/eeg_model3/standard_scaler.joblib\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 15. (可選) 保存類別名稱\u001b[39;00m\n\u001b[1;32m     53\u001b[0m class_names_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_names.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(class_names, class_names_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib  # 用於導出模型\n",
    "import os\n",
    "\n",
    "# 1. 加載數據\n",
    "file_path = '/Users/hoyi/Downloads/eeg_features_labels.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 2. 準備特徵和標籤\n",
    "X = data[['beta_mean', 'alpha_mean']].values\n",
    "y = data['label'].values\n",
    "\n",
    "# 3. 特徵標準化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ... [中間的代碼保持不變，直到最後的模型訓練部分] ...\n",
    "\n",
    "# 13. 訓練最終模型\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# 14. 導出模型和標準化器\n",
    "output_folder = '/Users/hoyi/Downloads/eeg_model3'\n",
    "os.makedirs(output_folder, exist_ok=True)  # 創建文件夾如果不存在\n",
    "\n",
    "# 保存模型\n",
    "model_path = os.path.join(output_folder, 'random_forest_model.joblib')\n",
    "joblib.dump(final_model, model_path)\n",
    "\n",
    "# 保存標準化器 (因為預測新數據時也需要相同的標準化)\n",
    "scaler_path = os.path.join(output_folder, 'standard_scaler.joblib')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f'\\n模型已成功導出至: {model_path}')\n",
    "print(f'標準化器已成功導出至: {scaler_path}')\n",
    "\n",
    "# 15. (可選) 保存類別名稱\n",
    "class_names_path = os.path.join(output_folder, 'class_names.joblib')\n",
    "joblib.dump(class_names, class_names_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4685af-7407-46c5-ba01-e37283536b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c28ca0-bee1-494f-828a-62ea60b10756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d62b8a-057b-4a1a-9744-dd90e1c0ac4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
